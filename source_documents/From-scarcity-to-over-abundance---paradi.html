<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>From scarcity to over abundance - paradigm change for IT departments (and others)</title>
</head>
<body>
<h1><a href="https://djon.es/blog/2008/03/15/from-scarcity-to-over-abundance-paradigm-change-for-it-departments-and-others/">From scarcity to over abundance - paradigm change for IT departments (and others)</a></h1>

<p>Tags: cognitiveEdge, design theory, elearning, enterprise 2.0, ple, Uncategorized, web 2.0 course sites</p>

<p>Nothing all that new in this post, at least not that others <a href="http://www.longtail.com/the_long_tail/2006/10/the_economics_o.html">haven't talked about previously</a>. But writing this helps me think about a few things.

<h3>Paradigms, good and bad</h3>

A <a href="http://en.wikipedia.org/wiki/Paradigm">paradigm</a> can be/has been defined as a particularly collection of beliefs and ways of seeing the world. Perhaps as the series of high level abstractions which a particular community create to enable very quick communication. For this purpose a common paradigm/collection of abstractions is incredibly useful, especially within a discipline.  It provides members of a community from throughout a wide geographic area with a shared language which they can use.

It also has a down side, <a href="http://en.wikipedia.org/wiki/Paradigm#Paradigm_Paralysis">paradigm paralysis</a>. The high level abstractions, the ways of seeing the world, become so ingrained that members of that community are unable to see outside of that paradigm. A good example is the <a href="http://www.nmm.ac.uk/server/show/conWebDoc.355">longitude problem</a> where established experts ignored an innovation from a non-expert because it fell outside of their paradigm, their way of looking at the world.

Based on my previous posts it is no great surprise to find out that I think that there is currently a similar problem going on with the practice of IT provision within organisations.

<h3>What's changed</h3>

The paradigm around organisational IT provision arose within a context that was very different.  A context that has existed for quite sometime, but is now under-going a significant shift caused by (at least) three factors
<ol>
  <li> The rise of really cheap, almost ubiquitous computer hardware. </li>
  <li> The rise of cheap (sometimes free), easy to use software. </li>
  <li> The spread of computer literacy beyond the high priests of ITD. </li>
</ol>

The major change is that what was once scarce and had to be managed as a scarce resource (hardware, software and expertise) is now available in abundance.

<h3>Hardware</h3>

From the 50s until recently, hardware was really, really expensive, generally under-powered and consequently had to be protected and managed.  For example, in the late 1960s in the USA there weren't too many human endeavours that would have had more available computing power than the <a href="http://www.abc.net.au/tv/guide/netw/200802/programs/ZY9091A001D11022008T212000.htm">Apollo 11 moon landing</a>. And yet, in modern terms, it was a pitifully under-resourced enterprise.

<a href="http://flickr.com/photos/pandaposse/2176676297/">Mission control</a>, the folk on earth responsible for controlling/supporting the flight had access to computer power equivalent to (probably less) than the Macbook Pro I'm writing this blog entry with. The <a href="http://flickr.com/photos/shinythings/153752411/">lunar module</a>, the bit that took the astronauts from moon orbit, down, and then back again is said to have had less power than the digital watch I am currently wearing.

<a href="http://en.wikipedia.org/wiki/Moore%27s_law">Moore's law</a> means that computer power increases exponentially with a similar impact on price.

<h3>Software</h3>

Software has traditionally been something you had to purchase.  Originally, only from the manufacturer of the hardware you used. Then software vendors arose, as hardware became more prevalent. Then there was public domain software, open source software and recently Web 2.0 software.

Not only was there more software available in these alternate approaches, this software became easier to use. There are at least half a dozen free blog services and a similar number of email services available on the Web.  All offering a better user experience than similar services provided by organisations.

<h3>Knowledge and literacy</h3>

The primitive nature of the "old" computers meant that they were very difficult to program and support. But since their introduction the ability to maintain and manipulate computers in order to achieve something useful has become increasingly easy.  Originally, it was only the academics, scientists and engineers who were designing computers who could maintain and manipulate them.  Eventually a profession arose around the maintenance and manipulation of computers.  As the evolution continued teenage boys of a certain social grouping became extremely proficient through to today when increasing numbers (but still not the majority) are able to maintain and manipulate computers to achieve their ends.

At the same time the spread of computers meant that more and more children grew up with computers. A number of the "uber-nerds" that grew up in the 60s and 70s had parents who worked in industries that enabled the nascent uber-nerds to access computers. To grow up with them. Today it is increasingly rare for anyone not to grow up with some familiarity with technology.

For example, Africa has the fastest growing adoption rate of <a href="http://en.wikipedia.org/wiki/Mobile_phone">mobile phones in the world</a>. I recently read that the diffusion of mobile phones in South Africa put at 98%.

Yes, there is still a place for professionals. But the increasing power and ease of use of computers means that their place is increasingly <strong>not</strong> about providing specialised services for a particular organisation, but instead providing generalised platforms which the increasingly informed general public can manipulate and use without the need for IT.

For example, there's an increasingly limited need (not quite no need) for an organisation to provide an email service when there are numerous free email services that are generally more reliable, more accessible and provide greater functionality than internal organisational services.

<h3>From scarcity to abundance</h3>

The paradigm of traditional IT governance etc is based around the idea that hardware, software and literacy are scarce.  This is no longer the case.  All are abundant. This implies that new approaches are possible, perhaps even desirable and necessary.

This isn't something that just applies to IT departments.  The line of work I'm in, broadly speaking "e-learning", is also influenced by this idea. The requirement for universities to provide learning management systems is becoming increasingly questionable, especially if you believe this change from scarcity to abundance suggests the need for a paradigm change.

The question for me is what will the new paradigm be? What problems will it create that need to be addressed?  Not just the problems caused by an old paradigm battling a new paradigm, the problems that the new paradigm will have. What shape will the new paradigm take? How can organisations make use of this change?

Some initial thoughts from others - <a href="http://www.kk.org/thetechnium/archives/2008/01/better_than_fre.php">better than free</a>.

A related question is what impact will this have on the design of learning and teaching?</p>

</body>
</html>
