<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Some ideas for e-learning indicators - releasing half-baked ideas</title>
</head>
<body>
<h1><a href="https://djon.es/blog/2009/02/17/some-ideas-for-e-learning-indicators-releasing-half-baked-ideas/">Some ideas for e-learning indicators - releasing half-baked ideas</a></h1>

<p>Tags: elearning, indicators, innovation, lmsEvaluation, Uncategorized</p>

<p><p>The following is a quick mind dump of ideas that have arisen today about how you might make use of the usage data and content of course websites from course management systems (CMS) to find out interesting things about learning and teaching. i.e. Col is aiming to develop <a href="http://beerc.wordpress.com/2008/12/21/more-on-the-indicators/">inidcators</a> that might be of use to the participants associated with e-learning - management, support staff, academics, students etc.</p>
<p>This post is an attempt to live up to some of the ideas of Jon Udell that I discussed <a href="https://djon.es/blog/2009/02/15/getting-half-baked-ideas-out-there-improving-research-and-the-academy/">in this post</a> about getting half-baked ideas out there.  Col and I have talked a bit today and I've also regained some prior thoughts that I'm putting down so we don't forget it.</p>
<p>The major benefit of getting these half-baked ideas out there are your thoughts.  What do you think? Want to share your half-baked ideas?</p>

<h3>The fundamental problem</h3>

<p>How do you identify/generate useful indicators that might be harnessed to act as weak signal detectors? How can we use all of this data about e-learning to generate something useful?</p>

<h3>Disclaimer</h3>

<p>It is fully understood that drawing simply upon usage data and other electronic data can <strong>never</strong> tell you the full story about a student's learning experience or the quality of the teaching. At best it can indicate that something might be there, in almost all cases further investigation would be required to be certain.</p>
<p>For example, lots of discussion on a course discussion forum with lots of people responding to each other might be indicative of a good learning experience.  It might be indicative of an out of control flame war.</p>
<p>However, knowing a little bit more about what's going on and applying it sensible will helpfully be of some use.</p>
<p>The following are propositions about what might be interesting indicators. These need to be tested, both quantatively and qualitatively.</p>

<h3>Content correlations?</h3>

<p>It's fairly widely accepted that most CMSes are generally used primarily as content repositories. Academics put lots of documents and other content into them for students to access. In some cases the ability of the CMS to act in some other purpose (e.g. to encourage discussion and collaboration) is significantly limited by the quality and variety of the tools they provide for these services and also some of the fundamental assumptions built into the CMSes (e.g. you have to login to acces the services).</p>
<p>If content is the primary use, is there anything useful that can be gained from. What I can think of includes:</p>
<ul>
  <li> If there is no or little information then this is bad. <br />If the course site doesn't contain anything, that's probably a sign of someone who is not engaging with teaching. Courses with little or no content could be a negative indicator. </li>
  <li> If the information is structured well, then it is good. <br />Poor structure again may indicate some less than knowledgable.  Almost all CMSes use a hierarchical structure for information.  If all the content is located within 1 of 7 parts of the hierarchy, things may not be good.</li>
  <li> If the content is heavily used, then this might imply usefulness. <br />If students are using content heavily and that heavy use is consistent across most content this might indicate well designed content, which might be a good thing.</li>
  <li> If the content is primarily the product of publishers, then this might be bad.<br />A course that relies almost entirely for content from a textbook publisher might suggest an experience that is not customised to the local context. It might suggest an academic taking the easy way out. Which might indicate a less than positive outcome. </li>
  <li> A large average # of hits on course content per student, might be  positive indicator.<br />If, on average, all of the students use the course content more, this may indicate more appropriate/useful material which might indicate a good learning experience.</li>
</ul>
<p>Looking for particularly strong courses (see images below) might lead to the following being of interest</p>
<ul>
  <li> Percentage of total content per course. <br />See images below. Essentially, courses with a greater percentage might be better. </li>
  <li> Percentage of total requests.
</ul>


<h3>Percentage of staff using the system</h3>

<p>A simple one, the greater the percentage of the employed teaching staff using the system, the better. </p>

<h3>An example</h3>

<p>The following images illustrate how this was used in <a href="http://www.slideshare.net/davidj/its-the-process-stupid-not-the-product">this presentation</a> to compare and contrast usage of Webfuse after a period using the wrong development process and then after a period of using a better development process (remember the disclaimer above).</p>

<h4>Results of "bad" process</h4>

<a href="http://www.flickr.com/photos/david_jones/3286237455/" title="Usage of an LMS - a measure (1 of 4) by David T Jones, on Flickr"><img alt="Usage of an LMS - a measure (1 of 4)" height="180" src="http://farm4.static.flickr.com/3644/3286237455_9933c51469_m.jpg" width="240" /></a>

<a href="http://www.flickr.com/photos/david_jones/3287054934/" title="Usage of an LMS - a measure (2 of 4) by David T Jones, on Flickr"><img alt="Usage of an LMS - a measure (2 of 4)" height="180" src="http://farm4.static.flickr.com/3642/3287054934_2d4214a64a_m.jpg" width="240" /></a>

<a href="http://www.flickr.com/photos/david_jones/3286238385/" title="Usage of an LMS - a measure (3 of 4) by David T Jones, on Flickr"><img alt="Usage of an LMS - a measure (3 of 4)" height="180" src="http://farm4.static.flickr.com/3567/3286238385_ef82ba9338_m.jpg" width="240" /></a>

<a href="http://www.flickr.com/photos/david_jones/3287055792/" title="Usage of an LMS - a measure (4 of 4) by David T Jones, on Flickr"><img alt="Usage of an LMS - a measure (4 of 4)" height="180" src="http://farm4.static.flickr.com/3166/3287055792_62f9666139_m.jpg" width="240" /></a>

<h4>Results of "good" process</h4>

<a href="http://www.flickr.com/photos/david_jones/3287056224/" title="Usage of an LMS - staff adoption (1 of 3) by David T Jones, on Flickr"><img alt="Usage of an LMS - staff adoption (1 of 3)" height="180" src="http://farm4.static.flickr.com/3395/3287056224_5d4fc668ec_m.jpg" width="240" /></a>

<a href="http://www.flickr.com/photos/david_jones/3287056668/" title="Usage of an LMS - staff adoption (2 of 3) by David T Jones, on Flickr"><img alt="Usage of an LMS - staff adoption (2 of 3)" height="180" src="http://farm4.static.flickr.com/3308/3287056668_fd07fb55a5_m.jpg" width="240" /></a>

<a href="http://www.flickr.com/photos/david_jones/3286240677/" title="Usage of an LMS - staff adoption (3 of 3) by David T Jones, on Flickr"><img alt="Usage of an LMS - staff adoption (3 of 3)" height="180" src="http://farm4.static.flickr.com/3201/3286240677_406ba8e2d5_m.jpg" width="240" /></a></p>

</body>
</html>
